
  
    
    

  

  
    
    

  

  
    
    

  

  
    
    

  

  
    
    

  

  
    
    

  

  
    
    

  

  
    
    

  

  
    
    

  


<!Doctype html>
<html id="docs" class="Support">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" type="image/png" href="/images/favicon.png">
    <link href='https://fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,400italic,500,500italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href='https://fonts.googleapis.com/css?family=Roboto+Mono' type='text/css'>
    <link rel="stylesheet" href="/css/styles.css"/>
    <link rel="stylesheet" href="/css/jquery-ui.min.css">
    <link rel="stylesheet" href="/css/sweetalert.css">
    
    <script src="/js/jquery-2.2.0.min.js"></script>
    <script src="/js/jquery-ui.min.js"></script>
    <script src="/js/script.js"></script>
    <script src="/js/sweetalert.min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <!-- Begin Jekyll SEO tag v2.1.0 -->
<title>Creating a Custom Cluster from Scratch - Kubernetes</title>
<meta property="og:title" content="Creating a Custom Cluster from Scratch" />
<meta name="description" content="Production-Grade Container Orchestration" />
<meta property="og:description" content="Production-Grade Container Orchestration" />
<link rel="canonical" href="http://localhost:4000/docs/getting-started-guides/scratch/" />
<meta property="og:url" content="http://localhost:4000/docs/getting-started-guides/scratch/" />
<meta property="og:site_name" content="Kubernetes" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@kubernetesio" />
<script type="application/ld+json">
{"@context": "http://schema.org",
"@type": "WebPage",
"headline": "Creating a Custom Cluster from Scratch",
"description": "Production-Grade Container Orchestration",
"publisher": {"@type": "Organization",
"logo": {"@type": "ImageObject",
"url": "http://localhost:4000/images/favicon.png"}},
"url": "http://localhost:4000/docs/getting-started-guides/scratch/"}</script>
<!-- End Jekyll SEO tag -->

</head>


<body>

<div id="cellophane" onclick="kub.toggleMenu()"></div>

<header>
    <a href="/" class="logo"></a>

    <div class="nav-buttons" data-auto-burger="primary">
        <ul class="global-nav">
            <li><a href="/docs/">Documentation</a></li>
            <li><a href="http://blog.kubernetes.io/">Blog</a></li>
            <li><a href="/partners/">Partners</a></li>
            <li><a href="/community/">Community</a></li>
            <li><a href="/case-studies/">Case Studies</a></li>
        </ul>
        <!-- <a href="/docs/" class="button" id="viewDocs" data-auto-burger-exclude>View Documentation</a> -->
        <a href="/docs/tutorials/kubernetes-basics/" class="button" id="tryKubernetes" data-auto-burger-exclude>Try Kubernetes</a>
        <button id="hamburger" onclick="kub.toggleMenu()" data-auto-burger-exclude><div></div></button>
    </div>

    <nav id="mainNav">
        <main data-auto-burger="primary">
        <div class="nav-box">
            <h3><a href="/docs/hellonode/">Get Started</a></h3>
            <p>Ready to get your hands dirty? Build a simple Kubernetes cluster that runs "Hello World" for Node.js.</p>
        </div>
        <div class="nav-box">
            <h3><a href="/docs/">Documentation</a></h3>
            <p>Learn how to use Kubernetes with the use of walkthroughs, samples, and reference documentation. You can even <a href="/editdocs/" data-auto-burger-exclude>help contribute to the docs</a>!</p>
        </div>
        <div class="nav-box">
            <h3><a href="/community/">Community</a></h3>
            <p>If you need help, you can connect with other Kubernetes users and the Kubernetes authors, attend community events, and watch video presentations from around the web.</p>
        </div>
        <div class="nav-box">
            <h3><a href="http://blog.kubernetes.io">Blog</a></h3>
            <p>Read the latest news for Kubernetes and the containers space in general, and get technical how-tos hot off the presses.</p>
        </div>
        </main>
        <main data-auto-burger="primary">
        <div class="left">
            <h5 class="github-invite">Interested in hacking on the core Kubernetes code base?</h5>
            <a href="https://github.com/kubernetes/kubernetes" class="button" data-auto-burger-exclude>View On Github</a>
        </div>

        <div class="right">
            <h5 class="github-invite">Explore the community</h5>
            <div class="social">
                <a href="https://twitter.com/kubernetesio" class="twitter"><span>Twitter</span></a>
                <a href="https://github.com/kubernetes/kubernetes" class="github"><span>Github</span></a>
                <a href="http://slack.k8s.io/" class="slack"><span>Slack</span></a>
                <a href="http://stackoverflow.com/questions/tagged/kubernetes" class="stack-overflow"><span>Stack Overflow</span></a>
                <a href="https://groups.google.com/forum/#!forum/kubernetes-users" class="mailing-list"><span>Mailing List</span></a>
                <a href="https://calendar.google.com/calendar/embed?src=nt2tcnbtbied3l6gi2h29slvc0%40group.calendar.google.com" class="calendar"><span>Events Calendar</span></a>
            </div>
        </div>
        <div class="clear" style="clear: both"></div>
        </main>
    </nav>
</header>


<!--  HERO  -->
<section id="hero" class="light-text">
  <h1>Support</h1>
  <h5>Troubleshooting resources, frequently asked questions, and community support channels.</h5>
  <div id="vendorStrip" class="light-text">
    <ul>
      <li><a href="/docs/" >DOCS HOME</a></li>
      <!-- <li><a href="/docs/user-guide/" >GUIDES</a></li> -->
      <li><a href="/docs/tutorials/" >TUTORIALS</a></li>
      <!-- <li><a href="/docs/tasks/" >TASKS</a></li> -->
      <li><a href="/docs/concepts/" >CONCEPTS</a></li>
      <li><a href="/docs/reference/" >REFERENCE</a></li>
      <li><a href="/docs/tools/" >TOOLS</a></li>
      <!-- <li><a href="/docs/samples/" >SAMPLES</a></li> -->
      <li><a href="/docs/troubleshooting/" class="YAH">SUPPORT</a></li>
    </ul>
    <div id="searchBox">
      <input type="text" id="search" placeholder="Search" onkeydown="if (event.keyCode==13) window.location.replace('/docs/search/?q=' + this.value)">
    </div>
  </div>
</section>

<section id="encyclopedia">
  <div id="docsToc">
        <div class="pi-accordion">
        
          
  

    

    
      <a class="item" data-title="Support" href="/docs/troubleshooting/"></a>
    
  

  
    <div class="item" data-title="Troubleshooting">
      <div class="container">
        
  

    

    
      <a class="item" data-title="User Guide" href="/docs/user-guide/"></a>
    
  


      </div>
    </div>
  

  
    <div class="item" data-title="Frequently Asked Questions">
      <div class="container">
        
  

    

    
      <a class="item" data-title="User FAQ" href="https://github.com/kubernetes/kubernetes/wiki/User-FAQ/"></a>
    
  

  

    

    
      <a class="item" data-title="Debugging FAQ" href="https://github.com/kubernetes/kubernetes/wiki/Debugging-FAQ/"></a>
    
  

  

    

    
      <a class="item" data-title="Services FAQ" href="https://github.com/kubernetes/kubernetes/wiki/Services-FAQ/"></a>
    
  


      </div>
    </div>
  

  
    <div class="item" data-title="Contributing to the Kubernetes Docs">
      <div class="container">
        
  

    

    
      <a class="item" data-title="Contributing to the Kubernetes Documentation" href="/editdocs/"></a>
    
  

  

    

    
      <a class="item" data-title="Creating a Documentation Pull Request" href="/docs/contribute/create-pull-request/"></a>
    
  

  

    

    
      <a class="item" data-title="Writing a New Topic" href="/docs/contribute/write-new-topic/"></a>
    
  

  

    

    
      <a class="item" data-title="Staging Your Documentation Changes" href="/docs/contribute/stage-documentation-changes/"></a>
    
  

  

    

    
      <a class="item" data-title="Using Page Templates" href="/docs/contribute/page-templates/"></a>
    
  

  

    

    
      <a class="item" data-title="Reviewing Documentation Issues" href="/docs/contribute/review-issues/"></a>
    
  

  

    

    
      <a class="item" data-title="Documentation Style Guide" href="/docs/contribute/style-guide/"></a>
    
  


      </div>
    </div>
  

  
    <div class="item" data-title="Other Resources">
      <div class="container">
        
  

    

    
      <a class="item" data-title="Kubernetes Issue Tracker on GitHub" href="https://github.com/kubernetes/kubernetes/issues/"></a>
    
  

  

    

    
      <a class="item" data-title="Report a Security Vulnerability" href="/docs/reporting-security-issues/"></a>
    
  

  

    

    
      <a class="item" data-title="Release Notes" href="https://github.com/kubernetes/kubernetes/releases/"></a>
    
  

  

    

    
      <a class="item" data-title="Release Roadmap" href="https://github.com/kubernetes/kubernetes/milestones/"></a>
    
  


      </div>
    </div>
  

  

    

    
      <a class="item" data-title="Deprecation Policy" href="/docs/deprecation-policy.md"></a>
    
  


        
        </div> <!-- /pi-accordion -->
    <button class="push-menu-close-button" onclick="kub.toggleToc()"></button>
  </div> <!-- /docsToc -->

  <div id="docsContent">
        <p><a href="/editdocs#docs/getting-started-guides/scratch.md" id="editPageButton">Edit This Page</a></p>

        
          <h1>Creating a Custom Cluster from Scratch</h1>
        

        <p>This guide is for people who want to craft a custom Kubernetes cluster.  If you
can find an existing Getting Started Guide that meets your needs on <a href="/docs/getting-started-guides/">this
list</a>, then we recommend using it, as you will be able to benefit
from the experience of others.  However, if you have specific IaaS, networking,
configuration management, or operating system requirements not met by any of
those guides, then this guide will provide an outline of the steps you need to
take.  Note that it requires considerably more effort than using one of the
pre-defined guides.</p>

<p>This guide is also useful for those wanting to understand at a high level some of the
steps that existing cluster setup scripts are making.</p>

<ul id="markdown-toc">
  <li><a href="#designing-and-preparing" id="markdown-toc-designing-and-preparing">Designing and Preparing</a>    <ul>
      <li><a href="#learning" id="markdown-toc-learning">Learning</a></li>
      <li><a href="#cloud-provider" id="markdown-toc-cloud-provider">Cloud Provider</a></li>
      <li><a href="#nodes" id="markdown-toc-nodes">Nodes</a></li>
      <li><a href="#network" id="markdown-toc-network">Network</a>        <ul>
          <li><a href="#network-connectivity" id="markdown-toc-network-connectivity">Network Connectivity</a></li>
          <li><a href="#network-policy" id="markdown-toc-network-policy">Network Policy</a></li>
        </ul>
      </li>
      <li><a href="#cluster-naming" id="markdown-toc-cluster-naming">Cluster Naming</a></li>
      <li><a href="#software-binaries" id="markdown-toc-software-binaries">Software Binaries</a>        <ul>
          <li><a href="#downloading-and-extracting-kubernetes-binaries" id="markdown-toc-downloading-and-extracting-kubernetes-binaries">Downloading and Extracting Kubernetes Binaries</a></li>
          <li><a href="#selecting-images" id="markdown-toc-selecting-images">Selecting Images</a></li>
        </ul>
      </li>
      <li><a href="#security-models" id="markdown-toc-security-models">Security Models</a>        <ul>
          <li><a href="#preparing-certs" id="markdown-toc-preparing-certs">Preparing Certs</a></li>
          <li><a href="#preparing-credentials" id="markdown-toc-preparing-credentials">Preparing Credentials</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#configuring-and-installing-base-software-on-nodes" id="markdown-toc-configuring-and-installing-base-software-on-nodes">Configuring and Installing Base Software on Nodes</a>    <ul>
      <li><a href="#docker" id="markdown-toc-docker">Docker</a></li>
      <li><a href="#rkt" id="markdown-toc-rkt">rkt</a></li>
      <li><a href="#kubelet" id="markdown-toc-kubelet">kubelet</a></li>
      <li><a href="#kube-proxy" id="markdown-toc-kube-proxy">kube-proxy</a></li>
      <li><a href="#networking" id="markdown-toc-networking">Networking</a></li>
      <li><a href="#other" id="markdown-toc-other">Other</a></li>
      <li><a href="#using-configuration-management" id="markdown-toc-using-configuration-management">Using Configuration Management</a></li>
    </ul>
  </li>
  <li><a href="#bootstrapping-the-cluster" id="markdown-toc-bootstrapping-the-cluster">Bootstrapping the Cluster</a>    <ul>
      <li><a href="#etcd" id="markdown-toc-etcd">etcd</a></li>
      <li><a href="#apiserver-controller-manager-and-scheduler" id="markdown-toc-apiserver-controller-manager-and-scheduler">Apiserver, Controller Manager, and Scheduler</a>        <ul>
          <li><a href="#apiserver-pod-template" id="markdown-toc-apiserver-pod-template">Apiserver pod template</a>            <ul>
              <li><a href="#cloud-providers" id="markdown-toc-cloud-providers">Cloud Providers</a></li>
            </ul>
          </li>
          <li><a href="#scheduler-pod-template" id="markdown-toc-scheduler-pod-template">Scheduler pod template</a></li>
          <li><a href="#controller-manager-template" id="markdown-toc-controller-manager-template">Controller Manager Template</a></li>
          <li><a href="#starting-and-verifying-apiserver-scheduler-and-controller-manager" id="markdown-toc-starting-and-verifying-apiserver-scheduler-and-controller-manager">Starting and Verifying Apiserver, Scheduler, and Controller Manager</a></li>
        </ul>
      </li>
      <li><a href="#starting-cluster-services" id="markdown-toc-starting-cluster-services">Starting Cluster Services</a></li>
    </ul>
  </li>
  <li><a href="#troubleshooting" id="markdown-toc-troubleshooting">Troubleshooting</a>    <ul>
      <li><a href="#running-validate-cluster" id="markdown-toc-running-validate-cluster">Running validate-cluster</a></li>
      <li><a href="#inspect-pods-and-services" id="markdown-toc-inspect-pods-and-services">Inspect pods and services</a></li>
      <li><a href="#try-examples" id="markdown-toc-try-examples">Try Examples</a></li>
      <li><a href="#running-the-conformance-test" id="markdown-toc-running-the-conformance-test">Running the Conformance Test</a></li>
      <li><a href="#networking-1" id="markdown-toc-networking-1">Networking</a></li>
      <li><a href="#getting-help" id="markdown-toc-getting-help">Getting Help</a></li>
    </ul>
  </li>
  <li><a href="#support-level" id="markdown-toc-support-level">Support Level</a></li>
</ul>

<h2 id="designing-and-preparing">Designing and Preparing</h2>

<h3 id="learning">Learning</h3>

<ol>
  <li>You should be familiar with using Kubernetes already.  We suggest you set
    up a temporary cluster by following one of the other Getting Started Guides.
    This will help you become familiar with the CLI (<a href="/docs/user-guide/kubectl/kubectl">kubectl</a>) and concepts (<a href="/docs/user-guide/pods">pods</a>, <a href="/docs/user-guide/services">services</a>, etc.) first.</li>
  <li>You should have <code class="highlighter-rouge">kubectl</code> installed on your desktop.  This will happen as a side
    effect of completing one of the other Getting Started Guides.  If not, follow the instructions
    <a href="/docs/user-guide/prereqs">here</a>.</li>
</ol>

<h3 id="cloud-provider">Cloud Provider</h3>

<p>Kubernetes has the concept of a Cloud Provider, which is a module which provides
an interface for managing TCP Load Balancers, Nodes (Instances) and Networking Routes.
The interface is defined in <code class="highlighter-rouge">pkg/cloudprovider/cloud.go</code>.  It is possible to
create a custom cluster without implementing a cloud provider (for example if using
bare-metal), and not all parts of the interface need to be implemented, depending
on how flags are set on various components.</p>

<h3 id="nodes">Nodes</h3>

<ul>
  <li>You can use virtual or physical machines.</li>
  <li>While you can build a cluster with 1 machine, in order to run all the examples and tests you
need at least 4 nodes.</li>
  <li>Many Getting-started-guides make a distinction between the master node and regular nodes.  This
is not strictly necessary.</li>
  <li>Nodes will need to run some version of Linux with the x86_64 architecture.  It may be possible
to run on other OSes and Architectures, but this guide does not try to assist with that.</li>
  <li>Apiserver and etcd together are fine on a machine with 1 core and 1GB RAM for clusters with 10s of nodes.
Larger or more active clusters may benefit from more cores.</li>
  <li>Other nodes can have any reasonable amount of memory and any number of cores.  They need not
have identical configurations.</li>
</ul>

<h3 id="network">Network</h3>

<h4 id="network-connectivity">Network Connectivity</h4>
<p>Kubernetes has a distinctive <a href="/docs/admin/networking">networking model</a>.</p>

<p>Kubernetes allocates an IP address to each pod.  When creating a cluster, you
need to allocate a block of IPs for Kubernetes to use as Pod IPs.  The simplest
approach is to allocate a different block of IPs to each node in the cluster as
the node is added.  A process in one pod should be able to communicate with
another pod using the IP of the second pod.  This connectivity can be
accomplished in two ways:</p>

<ul>
  <li><strong>Using an overlay network</strong>
    <ul>
      <li>An overlay network obscures the underlying network architecture from the 
pod network through traffic encapsulation (e.g. vxlan).</li>
      <li>Encapsulation reduces performance, though exactly how much depends on your solution.</li>
    </ul>
  </li>
  <li><strong>Without an overlay network</strong>
    <ul>
      <li>Configure the underlying network fabric (switches, routers, etc.) to be aware of pod IP addresses.</li>
      <li>This does not require the encapsulation provided by an overlay, and so can achieve 
better performance.</li>
    </ul>
  </li>
</ul>

<p>Which method you choose depends on your environment and requirements.  There are various ways 
to implement one of the above options:</p>

<ul>
  <li><strong>Use a network plugin which is called by Kubernetes</strong>
    <ul>
      <li>Kubernetes supports the <a href="https://github.com/containernetworking/cni">CNI</a> network plugin interface.</li>
      <li>There are a number of solutions which provide plugins for Kubernetes (listed alphabetically):
        <ul>
          <li><a href="http://docs.projectcalico.org/">Calico</a></li>
          <li><a href="https://github.com/coreos/flannel">Flannel</a></li>
          <li><a href="http://openvswitch.org/">Open vSwitch (OVS)</a></li>
          <li><a href="http://romana.io/">Romana</a></li>
          <li><a href="http://weave.works/">Weave</a></li>
          <li><a href="/docs/admin/networking#how-to-achieve-this">More found here</a></li>
        </ul>
      </li>
      <li>You can also write your own.</li>
    </ul>
  </li>
  <li><strong>Compile support directly into Kubernetes</strong>
    <ul>
      <li>This can be done by implementing the “Routes” interface of a Cloud Provider module.</li>
      <li>The Google Compute Engine (<a href="/docs/getting-started-guides/gce">GCE</a>) and <a href="/docs/getting-started-guides/aws">AWS</a> guides use this approach.</li>
    </ul>
  </li>
  <li><strong>Configure the network external to Kubernetes</strong>
    <ul>
      <li>This can be done by manually running commands, or through a set of externally maintained scripts.</li>
      <li>You have to implement this yourself, but it can give you an extra degree of flexibility.</li>
    </ul>
  </li>
</ul>

<p>You will need to select an address range for the Pod IPs. Note that IPv6 is not yet supported for Pod IPs.</p>

<ul>
  <li>Various approaches:
    <ul>
      <li>GCE: each project has its own <code class="highlighter-rouge">10.0.0.0/8</code>.  Carve off a <code class="highlighter-rouge">/16</code> for each
Kubernetes cluster from that space, which leaves room for several clusters.
Each node gets a further subdivision of this space.</li>
      <li>AWS: use one VPC for whole organization, carve off a chunk for each
cluster, or use different VPC for different clusters.</li>
    </ul>
  </li>
  <li>Allocate one CIDR subnet for each node’s PodIPs, or a single large CIDR
from which smaller CIDRs are automatically allocated to each node.
    <ul>
      <li>You need max-pods-per-node * max-number-of-nodes IPs in total. A <code class="highlighter-rouge">/24</code> per
node supports 254 pods per machine and is a common choice.  If IPs are
scarce, a <code class="highlighter-rouge">/26</code> (62 pods per machine) or even a <code class="highlighter-rouge">/27</code> (30 pods) may be sufficient.</li>
      <li>e.g. use <code class="highlighter-rouge">10.10.0.0/16</code> as the range for the cluster, with up to 256 nodes
using <code class="highlighter-rouge">10.10.0.0/24</code> through <code class="highlighter-rouge">10.10.255.0/24</code>, respectively.</li>
      <li>Need to make these routable or connect with overlay.</li>
    </ul>
  </li>
</ul>

<p>Kubernetes also allocates an IP to each <a href="/docs/user-guide/services">service</a>.  However,
service IPs do not necessarily need to be routable.  The kube-proxy takes care
of translating Service IPs to Pod IPs before traffic leaves the node.  You do
need to Allocate a block of IPs for services.  Call this
<code class="highlighter-rouge">SERVICE_CLUSTER_IP_RANGE</code>.  For example, you could set
<code class="highlighter-rouge">SERVICE_CLUSTER_IP_RANGE="10.0.0.0/16"</code>, allowing 65534 distinct services to
be active at once.  Note that you can grow the end of this range, but you
cannot move it without disrupting the services and pods that already use it.</p>

<p>Also, you need to pick a static IP for master node.</p>

<ul>
  <li>Call this <code class="highlighter-rouge">MASTER_IP</code>.</li>
  <li>Open any firewalls to allow access to the apiserver ports 80 and/or 443.</li>
  <li>Enable ipv4 forwarding sysctl, <code class="highlighter-rouge">net.ipv4.ip_forward = 1</code></li>
</ul>

<h4 id="network-policy">Network Policy</h4>

<p>Kubernetes enables the definition of fine-grained network policy between Pods using the <a href="/docs/user-guide/network-policy">NetworkPolicy</a> resource.</p>

<p>Not all networking providers support the Kubernetes NetworkPolicy API, see <a href="/docs/getting-started-guides/network-policy/walkthrough/">Using Network Policy</a> for more information.</p>

<h3 id="cluster-naming">Cluster Naming</h3>

<p>You should pick a name for your cluster.  Pick a short name for each cluster
which is unique from future cluster names. This will be used in several ways:</p>

<ul>
  <li>by kubectl to distinguish between various clusters you have access to.  You will probably want a
second one sometime later, such as for testing new Kubernetes releases, running in a different
region of the world, etc.</li>
  <li>Kubernetes clusters can create cloud provider resources (e.g. AWS ELBs) and different clusters
need to distinguish which resources each created.  Call this <code class="highlighter-rouge">CLUSTER_NAME</code>.</li>
</ul>

<h3 id="software-binaries">Software Binaries</h3>

<p>You will need binaries for:</p>

<ul>
  <li>etcd</li>
  <li>A container runner, one of:
    <ul>
      <li>docker</li>
      <li>rkt</li>
    </ul>
  </li>
  <li>Kubernetes
    <ul>
      <li>kubelet</li>
      <li>kube-proxy</li>
      <li>kube-apiserver</li>
      <li>kube-controller-manager</li>
      <li>kube-scheduler</li>
    </ul>
  </li>
</ul>

<h4 id="downloading-and-extracting-kubernetes-binaries">Downloading and Extracting Kubernetes Binaries</h4>

<p>A Kubernetes binary release includes all the Kubernetes binaries as well as the supported release of etcd.
You can use a Kubernetes binary release (recommended) or build your Kubernetes binaries following the instructions in the
<a href="https://github.com/kubernetes/kubernetes/tree/master/docs/devel/">Developer Documentation</a>.  Only using a binary release is covered in this guide.</p>

<p>Download the <a href="https://github.com/kubernetes/kubernetes/releases/latest">latest binary release</a> and unzip it.
Then locate <code class="highlighter-rouge">./kubernetes/server/kubernetes-server-linux-amd64.tar.gz</code> and unzip <em>that</em>.
Then, within the second set of unzipped files, locate <code class="highlighter-rouge">./kubernetes/server/bin</code>, which contains
all the necessary binaries.</p>

<h4 id="selecting-images">Selecting Images</h4>

<p>You will run docker, kubelet, and kube-proxy outside of a container, the same way you would run any system daemon, so
you just need the bare binaries.  For etcd, kube-apiserver, kube-controller-manager, and kube-scheduler,
we recommend that you run these as containers, so you need an image to be built.</p>

<p>You have several choices for Kubernetes images:</p>

<ul>
  <li>Use images hosted on Google Container Registry (GCR):
    <ul>
      <li>e.g. <code class="highlighter-rouge">gcr.io/google_containers/hyperkube:$TAG</code>, where <code class="highlighter-rouge">TAG</code> is the latest
release tag, which can be found on the <a href="https://github.com/kubernetes/kubernetes/releases/latest">latest releases page</a>.</li>
      <li>Ensure $TAG is the same tag as the release tag you are using for kubelet and kube-proxy.</li>
      <li>The <a href="https://releases.k8s.io/master/cmd/hyperkube">hyperkube</a> binary is an all in one binary
        <ul>
          <li><code class="highlighter-rouge">hyperkube kubelet ...</code> runs the kubelet, <code class="highlighter-rouge">hyperkube apiserver ...</code> runs an apiserver, etc.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Build your own images.
    <ul>
      <li>Useful if you are using a private registry.</li>
      <li>The release contains files such as <code class="highlighter-rouge">./kubernetes/server/bin/kube-apiserver.tar</code> which
can be converted into docker images using a command like
<code class="highlighter-rouge">docker load -i kube-apiserver.tar</code></li>
      <li>You can verify if the image is loaded successfully with the right repository and tag using
command like <code class="highlighter-rouge">docker images</code></li>
    </ul>
  </li>
</ul>

<p>For etcd, you can:</p>

<ul>
  <li>Use images hosted on Google Container Registry (GCR), such as <code class="highlighter-rouge">gcr.io/google_containers/etcd:2.2.1</code></li>
  <li>Use images hosted on <a href="https://hub.docker.com/search/?q=etcd">Docker Hub</a> or <a href="https://quay.io/repository/coreos/etcd">Quay.io</a>, such as <code class="highlighter-rouge">quay.io/coreos/etcd:v2.2.1</code></li>
  <li>Use etcd binary included in your OS distro.</li>
  <li>Build your own image
    <ul>
      <li>You can do: <code class="highlighter-rouge">cd kubernetes/cluster/images/etcd; make</code></li>
    </ul>
  </li>
</ul>

<p>We recommend that you use the etcd version which is provided in the Kubernetes binary distribution.   The Kubernetes binaries in the release
were tested extensively with this version of etcd and not with any other version.
The recommended version number can also be found as the value of <code class="highlighter-rouge">TAG</code> in <code class="highlighter-rouge">kubernetes/cluster/images/etcd/Makefile</code>.</p>

<p>The remainder of the document assumes that the image identifiers have been chosen and stored in corresponding env vars.  Examples (replace with latest tags and appropriate registry):</p>

<ul>
  <li><code class="highlighter-rouge">HYPERKUBE_IMAGE=gcr.io/google_containers/hyperkube:$TAG</code></li>
  <li><code class="highlighter-rouge">ETCD_IMAGE=gcr.io/google_containers/etcd:$ETCD_VERSION</code></li>
</ul>

<h3 id="security-models">Security Models</h3>

<p>There are two main options for security:</p>

<ul>
  <li>Access the apiserver using HTTP.
    <ul>
      <li>Use a firewall for security.</li>
      <li>This is easier to setup.</li>
    </ul>
  </li>
  <li>Access the apiserver using HTTPS
    <ul>
      <li>Use https with certs, and credentials for user.</li>
      <li>This is the recommended approach.</li>
      <li>Configuring certs can be tricky.</li>
    </ul>
  </li>
</ul>

<p>If following the HTTPS approach, you will need to prepare certs and credentials.</p>

<h4 id="preparing-certs">Preparing Certs</h4>

<p>You need to prepare several certs:</p>

<ul>
  <li>The master needs a cert to act as an HTTPS server.</li>
  <li>The kubelets optionally need certs to identify themselves as clients of the master, and when
serving its own API over HTTPS.</li>
</ul>

<p>Unless you plan to have a real CA generate your certs, you will need
to generate a root cert and use that to sign the master, kubelet, and
kubectl certs. How to do this is described in the <a href="/docs/admin/authentication/#creating-certificates">authentication
documentation</a>.</p>

<p>You will end up with the following files (we will use these variables later on)</p>

<ul>
  <li><code class="highlighter-rouge">CA_CERT</code>
    <ul>
      <li>put in on node where apiserver runs, in e.g. <code class="highlighter-rouge">/srv/kubernetes/ca.crt</code>.</li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">MASTER_CERT</code>
    <ul>
      <li>signed by CA_CERT</li>
      <li>put in on node where apiserver runs, in e.g. <code class="highlighter-rouge">/srv/kubernetes/server.crt</code></li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">MASTER_KEY </code>
    <ul>
      <li>put in on node where apiserver runs, in e.g. <code class="highlighter-rouge">/srv/kubernetes/server.key</code></li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">KUBELET_CERT</code>
    <ul>
      <li>optional</li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">KUBELET_KEY</code>
    <ul>
      <li>optional</li>
    </ul>
  </li>
</ul>

<h4 id="preparing-credentials">Preparing Credentials</h4>

<p>The admin user (and any users) need:</p>

<ul>
  <li>a token or a password to identify them.</li>
  <li>tokens are just long alphanumeric strings, e.g. 32 chars.  See
    <ul>
      <li><code class="highlighter-rouge">TOKEN=$(dd if=/dev/urandom bs=128 count=1 2&gt;/dev/null | base64 | tr -d "=+/" | dd bs=32 count=1 2&gt;/dev/null)</code></li>
    </ul>
  </li>
</ul>

<p>Your tokens and passwords need to be stored in a file for the apiserver
to read.  This guide uses <code class="highlighter-rouge">/var/lib/kube-apiserver/known_tokens.csv</code>.
The format for this file is described in the <a href="/docs/admin/authentication">authentication documentation</a>.</p>

<p>For distributing credentials to clients, the convention in Kubernetes is to put the credentials
into a <a href="/docs/user-guide/kubeconfig-file">kubeconfig file</a>.</p>

<p>The kubeconfig file for the administrator can be created as follows:</p>

<ul>
  <li>If you have already used Kubernetes with a non-custom cluster (for example, used a Getting Started
Guide), you will already have a <code class="highlighter-rouge">$HOME/.kube/config</code> file.</li>
  <li>You need to add certs, keys, and the master IP to the kubeconfig file:
    <ul>
      <li>If using the firewall-only security option, set the apiserver this way:
        <ul>
          <li><code class="highlighter-rouge">kubectl config set-cluster $CLUSTER_NAME --server=http://$MASTER_IP --insecure-skip-tls-verify=true</code></li>
        </ul>
      </li>
      <li>Otherwise, do this to set the apiserver ip, client certs, and user credentials.
        <ul>
          <li><code class="highlighter-rouge">kubectl config set-cluster $CLUSTER_NAME --certificate-authority=$CA_CERT --embed-certs=true --server=https://$MASTER_IP</code></li>
          <li><code class="highlighter-rouge">kubectl config set-credentials $USER --client-certificate=$CLI_CERT --client-key=$CLI_KEY --embed-certs=true --token=$TOKEN</code></li>
        </ul>
      </li>
      <li>Set your cluster as the default cluster to use:
        <ul>
          <li><code class="highlighter-rouge">kubectl config set-context $CONTEXT_NAME --cluster=$CLUSTER_NAME --user=$USER</code></li>
          <li><code class="highlighter-rouge">kubectl config use-context $CONTEXT_NAME</code></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>Next, make a kubeconfig file for the kubelets and kube-proxy.  There are a couple of options for how
many distinct files to make:</p>

<ol>
  <li>Use the same credential as the admin
    - This is simplest to setup.</li>
  <li>One token and kubeconfig file for all kubelets, one for all kube-proxy, one for admin.
    - This mirrors what is done on GCE today</li>
  <li>Different credentials for every kubelet, etc.
    - We are working on this but all the pieces are not ready yet.</li>
</ol>

<p>You can make the files by copying the <code class="highlighter-rouge">$HOME/.kube/config</code>, by following the code
in <code class="highlighter-rouge">cluster/gce/configure-vm.sh</code> or by using the following template:</p>

<div class="language-yaml highlighter-rouge"><pre class="highlight"><code><span class="s">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="s">kind</span><span class="pi">:</span> <span class="s">Config</span>
<span class="s">users</span><span class="pi">:</span>
<span class="pi">-</span> <span class="s">name</span><span class="pi">:</span> <span class="s">kubelet</span>
  <span class="s">user</span><span class="pi">:</span>
    <span class="s">token</span><span class="pi">:</span> <span class="s">${KUBELET_TOKEN}</span>
<span class="s">clusters</span><span class="pi">:</span>
<span class="pi">-</span> <span class="s">name</span><span class="pi">:</span> <span class="s">local</span>
  <span class="s">cluster</span><span class="pi">:</span>
    <span class="s">certificate-authority</span><span class="pi">:</span> <span class="s">/srv/kubernetes/ca.crt</span>
<span class="s">contexts</span><span class="pi">:</span>
<span class="pi">-</span> <span class="s">context</span><span class="pi">:</span>
    <span class="s">cluster</span><span class="pi">:</span> <span class="s">local</span>
    <span class="s">user</span><span class="pi">:</span> <span class="s">kubelet</span>
  <span class="s">name</span><span class="pi">:</span> <span class="s">service-account-context</span>
<span class="s">current-context</span><span class="pi">:</span> <span class="s">service-account-context</span>
</code></pre>
</div>

<p>Put the kubeconfig(s) on every node.  The examples later in this
guide assume that there are kubeconfigs in <code class="highlighter-rouge">/var/lib/kube-proxy/kubeconfig</code> and
<code class="highlighter-rouge">/var/lib/kubelet/kubeconfig</code>.</p>

<h2 id="configuring-and-installing-base-software-on-nodes">Configuring and Installing Base Software on Nodes</h2>

<p>This section discusses how to configure machines to be Kubernetes nodes.</p>

<p>You should run three daemons on every node:</p>

<ul>
  <li>docker or rkt</li>
  <li>kubelet</li>
  <li>kube-proxy</li>
</ul>

<p>You will also need to do assorted other configuration on top of a
base OS install.</p>

<p>Tip: One possible starting point is to setup a cluster using an existing Getting
Started Guide.   After getting a cluster running, you can then copy the init.d scripts or systemd unit files from that
cluster, and then modify them for use on your custom cluster.</p>

<h3 id="docker">Docker</h3>

<p>The minimum required Docker version will vary as the kubelet version changes.  The newest stable release is a good choice.  Kubelet will log a warning and refuse to start pods if the version is too old, so pick a version and try it.</p>

<p>If you previously had Docker installed on a node without setting Kubernetes-specific
options, you may have a Docker-created bridge and iptables rules.  You may want to remove these
as follows before proceeding to configure Docker for Kubernetes.</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code>iptables -t nat -F
ip link <span class="nb">set </span>docker0 down
ip link delete docker0
</code></pre>
</div>

<p>The way you configure docker will depend in whether you have chosen the routable-vip or overlay-network approaches for your network.
Some suggested docker options:</p>

<ul>
  <li>create your own bridge for the per-node CIDR ranges, call it cbr0, and set <code class="highlighter-rouge">--bridge=cbr0</code> option on docker.</li>
  <li>set <code class="highlighter-rouge">--iptables=false</code> so docker will not manipulate iptables for host-ports (too coarse on older docker versions, may be fixed in newer versions)
so that kube-proxy can manage iptables instead of docker.</li>
  <li><code class="highlighter-rouge">--ip-masq=false</code>
    <ul>
      <li>if you have setup PodIPs to be routable, then you want this false, otherwise, docker will
rewrite the PodIP source-address to a NodeIP.</li>
      <li>some environments (e.g. GCE) still need you to masquerade out-bound traffic when it leaves the cloud environment. This is very environment specific.</li>
      <li>if you are using an overlay network, consult those instructions.</li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">--mtu=</code>
    <ul>
      <li>may be required when using Flannel, because of the extra packet size due to udp encapsulation</li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">--insecure-registry $CLUSTER_SUBNET</code>
    <ul>
      <li>to connect to a private registry, if you set one up, without using SSL.</li>
    </ul>
  </li>
</ul>

<p>You may want to increase the number of open files for docker:</p>

<ul>
  <li><code class="highlighter-rouge">DOCKER_NOFILE=1000000</code></li>
</ul>

<p>Where this config goes depends on your node OS.  For example, GCE’s Debian-based distro uses <code class="highlighter-rouge">/etc/default/docker</code>.</p>

<p>Ensure docker is working correctly on your system before proceeding with the rest of the
installation, by following examples given in the Docker documentation.</p>

<h3 id="rkt">rkt</h3>

<p><a href="https://github.com/coreos/rkt">rkt</a> is an alternative to Docker.  You only need to install one of Docker or rkt.
The minimum version required is <a href="https://github.com/coreos/rkt/releases/tag/v0.5.6">v0.5.6</a>.</p>

<p><a href="http://www.freedesktop.org/wiki/Software/systemd/">systemd</a> is required on your node to run rkt.  The
minimum version required to match rkt v0.5.6 is
<a href="http://lists.freedesktop.org/archives/systemd-devel/2014-July/020903.html">systemd 215</a>.</p>

<p><a href="https://github.com/coreos/rkt/blob/master/Documentation/networking/overview.md">rkt metadata service</a> is also required
for rkt networking support.  You can start rkt metadata service by using command like
<code class="highlighter-rouge">sudo systemd-run rkt metadata-service</code></p>

<p>Then you need to configure your kubelet with flag:</p>

<ul>
  <li><code class="highlighter-rouge">--container-runtime=rkt</code></li>
</ul>

<h3 id="kubelet">kubelet</h3>

<p>All nodes should run kubelet.  See <a href="#software-binaries">Software Binaries</a>.</p>

<p>Arguments to consider:</p>

<ul>
  <li>If following the HTTPS security approach:
    <ul>
      <li><code class="highlighter-rouge">--api-servers=https://$MASTER_IP</code></li>
      <li><code class="highlighter-rouge">--kubeconfig=/var/lib/kubelet/kubeconfig</code></li>
    </ul>
  </li>
  <li>Otherwise, if taking the firewall-based security approach
    <ul>
      <li><code class="highlighter-rouge">--api-servers=http://$MASTER_IP</code></li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">--config=/etc/kubernetes/manifests</code></li>
  <li><code class="highlighter-rouge">--cluster-dns=</code> to the address of the DNS server you will setup (see <a href="#starting-cluster-services">Starting Cluster Services</a>.)</li>
  <li><code class="highlighter-rouge">--cluster-domain=</code> to the dns domain prefix to use for cluster DNS addresses.</li>
  <li><code class="highlighter-rouge">--docker-root=</code></li>
  <li><code class="highlighter-rouge">--root-dir=</code></li>
  <li><code class="highlighter-rouge">--configure-cbr0=</code> (described below)</li>
  <li><code class="highlighter-rouge">--register-node</code> (described in <a href="/docs/admin/node">Node</a> documentation.)</li>
</ul>

<h3 id="kube-proxy">kube-proxy</h3>

<p>All nodes should run kube-proxy.  (Running kube-proxy on a “master” node is not
strictly required, but being consistent is easier.)   Obtain a binary as described for
kubelet.</p>

<p>Arguments to consider:</p>

<ul>
  <li>If following the HTTPS security approach:
    <ul>
      <li><code class="highlighter-rouge">--master=https://$MASTER_IP</code></li>
      <li><code class="highlighter-rouge">--kubeconfig=/var/lib/kube-proxy/kubeconfig</code></li>
    </ul>
  </li>
  <li>Otherwise, if taking the firewall-based security approach
    <ul>
      <li><code class="highlighter-rouge">--master=http://$MASTER_IP</code></li>
    </ul>
  </li>
</ul>

<h3 id="networking">Networking</h3>

<p>Each node needs to be allocated its own CIDR range for pod networking.
Call this <code class="highlighter-rouge">NODE_X_POD_CIDR</code>.</p>

<p>A bridge called <code class="highlighter-rouge">cbr0</code> needs to be created on each node.  The bridge is explained
further in the <a href="/docs/admin/networking">networking documentation</a>.  The bridge itself
needs an address from <code class="highlighter-rouge">$NODE_X_POD_CIDR</code> - by convention the first IP.  Call
this <code class="highlighter-rouge">NODE_X_BRIDGE_ADDR</code>.  For example, if <code class="highlighter-rouge">NODE_X_POD_CIDR</code> is <code class="highlighter-rouge">10.0.0.0/16</code>,
then <code class="highlighter-rouge">NODE_X_BRIDGE_ADDR</code> is <code class="highlighter-rouge">10.0.0.1/16</code>.  NOTE: this retains the <code class="highlighter-rouge">/16</code> suffix
because of how this is used later.</p>

<ul>
  <li>
    <p>Recommended, automatic approach:</p>

    <ol>
      <li>Set <code class="highlighter-rouge">--configure-cbr0=true</code> option in kubelet init script and restart kubelet service.  Kubelet will configure cbr0 automatically.
It will wait to do this until the node controller has set Node.Spec.PodCIDR.  Since you have not setup apiserver and node controller
yet, the bridge will not be setup immediately.</li>
    </ol>
  </li>
  <li>
    <p>Alternate, manual approach:</p>

    <ol>
      <li>Set <code class="highlighter-rouge">--configure-cbr0=false</code> on kubelet and restart.</li>
      <li>Create a bridge
        <ul>
          <li><code class="highlighter-rouge">ip link add name cbr0 type bridge</code>.</li>
        </ul>
      </li>
      <li>Set appropriate MTU. NOTE: the actual value of MTU will depend on your network environment
        <ul>
          <li><code class="highlighter-rouge">ip link set dev cbr0 mtu 1460</code></li>
        </ul>
      </li>
      <li>Add the node’s network to the bridge (docker will go on other side of bridge).
        <ul>
          <li><code class="highlighter-rouge">ip addr add $NODE_X_BRIDGE_ADDR dev cbr0</code></li>
        </ul>
      </li>
      <li>Turn it on
        <ul>
          <li><code class="highlighter-rouge">ip link set dev cbr0 up</code></li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p>If you have turned off Docker’s IP masquerading to allow pods to talk to each
other, then you may need to do masquerading just for destination IPs outside
the cluster network.  For example:</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code>iptables -t nat -A POSTROUTING ! -d <span class="k">${</span><span class="nv">CLUSTER_SUBNET</span><span class="k">}</span> -m addrtype ! --dst-type LOCAL -j MASQUERADE
</code></pre>
</div>

<p>This will rewrite the source address from
the PodIP to the Node IP for traffic bound outside the cluster, and kernel
<a href="http://www.iptables.info/en/connection-state.html">connection tracking</a>
will ensure that responses destined to the node still reach
the pod.</p>

<p>NOTE: This is environment specific.  Some environments will not need
any masquerading at all.  Others, such as GCE, will not allow pod IPs to send
traffic to the internet, but have no problem with them inside your GCE Project.</p>

<h3 id="other">Other</h3>

<ul>
  <li>Enable auto-upgrades for your OS package manager, if desired.</li>
  <li>Configure log rotation for all node components (e.g. using <a href="http://linux.die.net/man/8/logrotate">logrotate</a>).</li>
  <li>Setup liveness-monitoring (e.g. using <a href="http://supervisord.org/">supervisord</a>).</li>
  <li>Setup volume plugin support (optional)
    <ul>
      <li>Install any client binaries for optional volume types, such as <code class="highlighter-rouge">glusterfs-client</code> for GlusterFS
volumes.</li>
    </ul>
  </li>
</ul>

<h3 id="using-configuration-management">Using Configuration Management</h3>

<p>The previous steps all involved “conventional” system administration techniques for setting up
machines.  You may want to use a Configuration Management system to automate the node configuration
process.  There are examples of <a href="/docs/admin/salt">Saltstack</a>, Ansible, Juju, and CoreOS Cloud Config in the
various Getting Started Guides.</p>

<h2 id="bootstrapping-the-cluster">Bootstrapping the Cluster</h2>

<p>While the basic node services (kubelet, kube-proxy, docker) are typically started and managed using
traditional system administration/automation approaches, the remaining <em>master</em> components of Kubernetes are
all configured and managed <em>by Kubernetes</em>:</p>

<ul>
  <li>their options are specified in a Pod spec (yaml or json) rather than an /etc/init.d file or
systemd unit.</li>
  <li>they are kept running by Kubernetes rather than by init.</li>
</ul>

<h3 id="etcd">etcd</h3>

<p>You will need to run one or more instances of etcd.</p>

<ul>
  <li>Recommended approach: run one etcd instance, with its log written to a directory backed
by durable storage (RAID, GCE PD)</li>
  <li>Alternative: run 3 or 5 etcd instances.
    <ul>
      <li>Log can be written to non-durable storage because storage is replicated.</li>
      <li>run a single apiserver which connects to one of the etcd nodes.</li>
    </ul>
  </li>
</ul>

<p>See <a href="/docs/admin/cluster-troubleshooting">cluster-troubleshooting</a> for more discussion on factors affecting cluster
availability.</p>

<p>To run an etcd instance:</p>

<ol>
  <li>Copy <code class="highlighter-rouge">cluster/saltbase/salt/etcd/etcd.manifest</code></li>
  <li>Make any modifications needed</li>
  <li>Start the pod by putting it into the kubelet manifest directory</li>
</ol>

<h3 id="apiserver-controller-manager-and-scheduler">Apiserver, Controller Manager, and Scheduler</h3>

<p>The apiserver, controller manager, and scheduler will each run as a pod on the master node.</p>

<p>For each of these components, the steps to start them running are similar:</p>

<ol>
  <li>Start with a provided template for a pod.</li>
  <li>Set the <code class="highlighter-rouge">HYPERKUBE_IMAGE</code> to the values chosen in <a href="#selecting-images">Selecting Images</a>.</li>
  <li>Determine which flags are needed for your cluster, using the advice below each template.</li>
  <li>Set the flags to be individual strings in the command array (e.g. $ARGN below)</li>
  <li>Start the pod by putting the completed template into the kubelet manifest directory.</li>
  <li>Verify that the pod is started.</li>
</ol>

<h4 id="apiserver-pod-template">Apiserver pod template</h4>

<div class="language-json highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nt">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Pod"</span><span class="p">,</span><span class="w">
  </span><span class="nt">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nt">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-apiserver"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nt">"spec"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"hostNetwork"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
    </span><span class="nt">"containers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w">
        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-apiserver"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"image"</span><span class="p">:</span><span class="w"> </span><span class="s2">"${HYPERKUBE_IMAGE}"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"command"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="s2">"/hyperkube"</span><span class="p">,</span><span class="w">
          </span><span class="s2">"apiserver"</span><span class="p">,</span><span class="w">
          </span><span class="s2">"$ARG1"</span><span class="p">,</span><span class="w">
          </span><span class="s2">"$ARG2"</span><span class="p">,</span><span class="w">
          </span><span class="err">...</span><span class="w">
          </span><span class="s2">"$ARGN"</span><span class="w">
        </span><span class="p">],</span><span class="w">
        </span><span class="nt">"ports"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="p">{</span><span class="w">
            </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"hostPort"</span><span class="p">:</span><span class="w"> </span><span class="mi">443</span><span class="p">,</span><span class="w">
            </span><span class="nt">"containerPort"</span><span class="p">:</span><span class="w"> </span><span class="mi">443</span><span class="w">
          </span><span class="p">},</span><span class="w">
          </span><span class="p">{</span><span class="w">
            </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"local"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"hostPort"</span><span class="p">:</span><span class="w"> </span><span class="mi">8080</span><span class="p">,</span><span class="w">
            </span><span class="nt">"containerPort"</span><span class="p">:</span><span class="w"> </span><span class="mi">8080</span><span class="w">
          </span><span class="p">}</span><span class="w">
        </span><span class="p">],</span><span class="w">
        </span><span class="nt">"volumeMounts"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="p">{</span><span class="w">
            </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"srvkube"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"mountPath"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/srv/kubernetes"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"readOnly"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
          </span><span class="p">},</span><span class="w">
          </span><span class="p">{</span><span class="w">
            </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"etcssl"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"mountPath"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/etc/ssl"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"readOnly"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
          </span><span class="p">}</span><span class="w">
        </span><span class="p">],</span><span class="w">
        </span><span class="nt">"livenessProbe"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nt">"httpGet"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nt">"scheme"</span><span class="p">:</span><span class="w"> </span><span class="s2">"HTTP"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"host"</span><span class="p">:</span><span class="w"> </span><span class="s2">"127.0.0.1"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"port"</span><span class="p">:</span><span class="w"> </span><span class="mi">8080</span><span class="p">,</span><span class="w">
            </span><span class="nt">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/healthz"</span><span class="w">
          </span><span class="p">},</span><span class="w">
          </span><span class="nt">"initialDelaySeconds"</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="p">,</span><span class="w">
          </span><span class="nt">"timeoutSeconds"</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="w">
        </span><span class="p">}</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nt">"volumes"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w">
        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"srvkube"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"hostPath"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nt">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/srv/kubernetes"</span><span class="w">
        </span><span class="p">}</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w">
        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"etcssl"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"hostPath"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nt">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/etc/ssl"</span><span class="w">
        </span><span class="p">}</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
</div>

<p>Here are some apiserver flags you may need to set:</p>

<ul>
  <li><code class="highlighter-rouge">--cloud-provider=</code> see <a href="#cloud-providers">cloud providers</a></li>
  <li><code class="highlighter-rouge">--cloud-config=</code> see <a href="#cloud-providers">cloud providers</a></li>
  <li><code class="highlighter-rouge">--address=${MASTER_IP}</code> <em>or</em> <code class="highlighter-rouge">--bind-address=127.0.0.1</code> and <code class="highlighter-rouge">--address=127.0.0.1</code> if you want to run a proxy on the master node.</li>
  <li><code class="highlighter-rouge">--cluster-name=$CLUSTER_NAME</code></li>
  <li><code class="highlighter-rouge">--service-cluster-ip-range=$SERVICE_CLUSTER_IP_RANGE</code></li>
  <li><code class="highlighter-rouge">--etcd-servers=http://127.0.0.1:4001</code></li>
  <li><code class="highlighter-rouge">--tls-cert-file=/srv/kubernetes/server.cert</code></li>
  <li><code class="highlighter-rouge">--tls-private-key-file=/srv/kubernetes/server.key</code></li>
  <li><code class="highlighter-rouge">--admission-control=$RECOMMENDED_LIST</code>
    <ul>
      <li>See <a href="/docs/admin/admission-controllers">admission controllers</a> for recommended arguments.</li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">--allow-privileged=true</code>, only if you trust your cluster user to run pods as root.</li>
</ul>

<p>If you are following the firewall-only security approach, then use these arguments:</p>

<ul>
  <li><code class="highlighter-rouge">--token-auth-file=/dev/null</code></li>
  <li><code class="highlighter-rouge">--insecure-bind-address=$MASTER_IP</code></li>
  <li><code class="highlighter-rouge">--advertise-address=$MASTER_IP</code></li>
</ul>

<p>If you are using the HTTPS approach, then set:</p>

<ul>
  <li><code class="highlighter-rouge">--client-ca-file=/srv/kubernetes/ca.crt</code></li>
  <li><code class="highlighter-rouge">--token-auth-file=/srv/kubernetes/known_tokens.csv</code></li>
  <li><code class="highlighter-rouge">--basic-auth-file=/srv/kubernetes/basic_auth.csv</code></li>
</ul>

<p>This pod mounts several node file system directories using the  <code class="highlighter-rouge">hostPath</code> volumes.  Their purposes are:</p>

<ul>
  <li>The <code class="highlighter-rouge">/etc/ssl</code> mount allows the apiserver to find the SSL root certs so it can
authenticate external services, such as a cloud provider.
    <ul>
      <li>This is not required if you do not use a cloud provider (e.g. bare-metal).</li>
    </ul>
  </li>
  <li>The <code class="highlighter-rouge">/srv/kubernetes</code> mount allows the apiserver to read certs and credentials stored on the
node disk.  These could instead be stored on a persistent disk, such as a GCE PD, or baked into the image.</li>
  <li>Optionally, you may want to mount <code class="highlighter-rouge">/var/log</code> as well and redirect output there (not shown in template).
    <ul>
      <li>Do this if you prefer your logs to be accessible from the root filesystem with tools like journalctl.</li>
    </ul>
  </li>
</ul>

<p><em>TODO</em> document proxy-ssh setup.</p>

<h5 id="cloud-providers">Cloud Providers</h5>

<p>Apiserver supports several cloud providers.</p>

<ul>
  <li>options for <code class="highlighter-rouge">--cloud-provider</code> flag are <code class="highlighter-rouge">aws</code>, <code class="highlighter-rouge">azure</code>, <code class="highlighter-rouge">cloudstack</code>, <code class="highlighter-rouge">fake</code>, <code class="highlighter-rouge">gce</code>, <code class="highlighter-rouge">mesos</code>, <code class="highlighter-rouge">openstack</code>, <code class="highlighter-rouge">ovirt</code>, <code class="highlighter-rouge">photon</code>, <code class="highlighter-rouge">rackspace</code>, <code class="highlighter-rouge">vsphere</code>, or unset.</li>
  <li>unset used for e.g. bare metal setups.</li>
  <li>support for new IaaS is added by contributing code <a href="https://releases.k8s.io/master/pkg/cloudprovider/providers">here</a></li>
</ul>

<p>Some cloud providers require a config file. If so, you need to put config file into apiserver image or mount through hostPath.</p>

<ul>
  <li><code class="highlighter-rouge">--cloud-config=</code> set if cloud provider requires a config file.</li>
  <li>Used by <code class="highlighter-rouge">aws</code>, <code class="highlighter-rouge">gce</code>, <code class="highlighter-rouge">mesos</code>, <code class="highlighter-rouge">openshift</code>, <code class="highlighter-rouge">ovirt</code> and <code class="highlighter-rouge">rackspace</code>.</li>
  <li>You must put config file into apiserver image or mount through hostPath.</li>
  <li>Cloud config file syntax is <a href="https://code.google.com/p/gcfg/">Gcfg</a>.</li>
  <li>AWS format defined by type <a href="https://releases.k8s.io/master/pkg/cloudprovider/providers/aws/aws.go">AWSCloudConfig</a></li>
  <li>There is a similar type in the corresponding file for other cloud providers.</li>
  <li>GCE example: search for <code class="highlighter-rouge">gce.conf</code> in <a href="https://releases.k8s.io/master/cluster/gce/configure-vm.sh">this file</a></li>
</ul>

<h4 id="scheduler-pod-template">Scheduler pod template</h4>

<p>Complete this template for the scheduler pod:</p>

<div class="language-json highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nt">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Pod"</span><span class="p">,</span><span class="w">
  </span><span class="nt">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nt">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-scheduler"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nt">"spec"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"hostNetwork"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
    </span><span class="nt">"containers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w">
        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-scheduler"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"image"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$HYBERKUBE_IMAGE"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"command"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="s2">"/hyperkube"</span><span class="p">,</span><span class="w">
          </span><span class="s2">"scheduler"</span><span class="p">,</span><span class="w">
          </span><span class="s2">"--master=127.0.0.1:8080"</span><span class="p">,</span><span class="w">
          </span><span class="s2">"$SCHEDULER_FLAG1"</span><span class="p">,</span><span class="w">
          </span><span class="err">...</span><span class="w">
          </span><span class="s2">"$SCHEDULER_FLAGN"</span><span class="w">
        </span><span class="p">],</span><span class="w">
        </span><span class="nt">"livenessProbe"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nt">"httpGet"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nt">"scheme"</span><span class="p">:</span><span class="w"> </span><span class="s2">"HTTP"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"host"</span><span class="p">:</span><span class="w"> </span><span class="s2">"127.0.0.1"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"port"</span><span class="p">:</span><span class="w"> </span><span class="mi">10251</span><span class="p">,</span><span class="w">
            </span><span class="nt">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/healthz"</span><span class="w">
          </span><span class="p">},</span><span class="w">
          </span><span class="nt">"initialDelaySeconds"</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="p">,</span><span class="w">
          </span><span class="nt">"timeoutSeconds"</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="w">
        </span><span class="p">}</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
</div>

<p>Typically, no additional flags are required for the scheduler.</p>

<p>Optionally, you may want to mount <code class="highlighter-rouge">/var/log</code> as well and redirect output there.</p>

<h4 id="controller-manager-template">Controller Manager Template</h4>

<p>Template for controller manager pod:</p>

<div class="language-json highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nt">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Pod"</span><span class="p">,</span><span class="w">
  </span><span class="nt">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nt">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-controller-manager"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nt">"spec"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"hostNetwork"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
    </span><span class="nt">"containers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w">
        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-controller-manager"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"image"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$HYPERKUBE_IMAGE"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"command"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="s2">"/hyperkube"</span><span class="p">,</span><span class="w">
          </span><span class="s2">"controller-manager"</span><span class="p">,</span><span class="w">
          </span><span class="s2">"$CNTRLMNGR_FLAG1"</span><span class="p">,</span><span class="w">
          </span><span class="err">...</span><span class="w">
          </span><span class="s2">"$CNTRLMNGR_FLAGN"</span><span class="w">
        </span><span class="p">],</span><span class="w">
        </span><span class="nt">"volumeMounts"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="p">{</span><span class="w">
            </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"srvkube"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"mountPath"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/srv/kubernetes"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"readOnly"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
          </span><span class="p">},</span><span class="w">
          </span><span class="p">{</span><span class="w">
            </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"etcssl"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"mountPath"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/etc/ssl"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"readOnly"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
          </span><span class="p">}</span><span class="w">
        </span><span class="p">],</span><span class="w">
        </span><span class="nt">"livenessProbe"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nt">"httpGet"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nt">"scheme"</span><span class="p">:</span><span class="w"> </span><span class="s2">"HTTP"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"host"</span><span class="p">:</span><span class="w"> </span><span class="s2">"127.0.0.1"</span><span class="p">,</span><span class="w">
            </span><span class="nt">"port"</span><span class="p">:</span><span class="w"> </span><span class="mi">10252</span><span class="p">,</span><span class="w">
            </span><span class="nt">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/healthz"</span><span class="w">
          </span><span class="p">},</span><span class="w">
          </span><span class="nt">"initialDelaySeconds"</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="p">,</span><span class="w">
          </span><span class="nt">"timeoutSeconds"</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="w">
        </span><span class="p">}</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nt">"volumes"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w">
        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"srvkube"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"hostPath"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nt">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/srv/kubernetes"</span><span class="w">
        </span><span class="p">}</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w">
        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"etcssl"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"hostPath"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nt">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/etc/ssl"</span><span class="w">
        </span><span class="p">}</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
</div>

<p>Flags to consider using with controller manager:</p>

<ul>
  <li><code class="highlighter-rouge">--cluster-name=$CLUSTER_NAME</code></li>
  <li><code class="highlighter-rouge">--cluster-cidr=</code>, the CIDR range for pods in cluster.</li>
  <li><code class="highlighter-rouge">--allocate-node-cidrs=</code>, if you are using <code class="highlighter-rouge">--cloud-provider=</code>, allocate and set the CIDRs for pods on the cloud provider.</li>
  <li><code class="highlighter-rouge">--cloud-provider=</code> and <code class="highlighter-rouge">--cloud-config</code> as described in apiserver section.</li>
  <li><code class="highlighter-rouge">--service-account-private-key-file=/srv/kubernetes/server.key</code>, used by the <a href="/docs/user-guide/service-accounts">service account</a> feature.</li>
  <li><code class="highlighter-rouge">--master=127.0.0.1:8080</code></li>
</ul>

<h4 id="starting-and-verifying-apiserver-scheduler-and-controller-manager">Starting and Verifying Apiserver, Scheduler, and Controller Manager</h4>

<p>Place each completed pod template into the kubelet config dir
(whatever <code class="highlighter-rouge">--config=</code> argument of kubelet is set to, typically
<code class="highlighter-rouge">/etc/kubernetes/manifests</code>).  The order does not matter: scheduler and
controller manager will retry reaching the apiserver until it is up.</p>

<p>Use <code class="highlighter-rouge">ps</code> or <code class="highlighter-rouge">docker ps</code> to verify that each process has started.  For example, verify that kubelet has started a container for the apiserver like this:</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo docker ps | grep apiserver:
5783290746d5        gcr.io/google_containers/kube-apiserver:e36bf367342b5a80d7467fd7611ad873            <span class="s2">"/bin/sh -c '/usr/lo'"</span>    10 seconds ago      Up 9 seconds                              k8s_kube-apiserver.feb145e7_kube-apiserver-kubernetes-master_default_eaebc600cf80dae59902b44225f2fc0a_225a4695
</code></pre>
</div>

<p>Then try to connect to the apiserver:</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span><span class="nb">echo</span> <span class="k">$(</span>curl -s http://localhost:8080/healthz<span class="k">)</span>
ok
<span class="gp">$ </span>curl -s http://localhost:8080/api
<span class="o">{</span>
  <span class="s2">"versions"</span>: <span class="o">[</span>
    <span class="s2">"v1"</span>
  <span class="o">]</span>
<span class="o">}</span>
</code></pre>
</div>

<p>If you have selected the <code class="highlighter-rouge">--register-node=true</code> option for kubelets, they will now begin self-registering with the apiserver.
You should soon be able to see all your nodes by running the <code class="highlighter-rouge">kubectl get nodes</code> command.
Otherwise, you will need to manually create node objects.</p>

<h3 id="starting-cluster-services">Starting Cluster Services</h3>

<p>You will want to complete your Kubernetes clusters by adding cluster-wide
services.  These are sometimes called <em>addons</em>, and <a href="/docs/admin/cluster-components/#addons">an overview
of their purpose is in the admin guide</a>.</p>

<p>Notes for setting up each cluster service are given below:</p>

<ul>
  <li>Cluster DNS:
    <ul>
      <li>required for many Kubernetes examples</li>
      <li><a href="http://releases.k8s.io/master/cluster/addons/dns/">Setup instructions</a></li>
      <li><a href="/docs/admin/dns/">Admin Guide</a></li>
    </ul>
  </li>
  <li>Cluster-level Logging
    <ul>
      <li><a href="/docs/user-guide/logging/overview">Cluster-level Logging Overview</a></li>
      <li><a href="/docs/user-guide/logging/elasticsearch">Cluster-level Logging with Elasticsearch</a></li>
      <li><a href="/docs/user-guide/logging/stackdriver">Cluster-level Logging with Stackdriver Logging</a></li>
    </ul>
  </li>
  <li>Container Resource Monitoring
    <ul>
      <li><a href="http://releases.k8s.io/master/cluster/addons/cluster-monitoring/">Setup instructions</a></li>
    </ul>
  </li>
  <li>GUI
    <ul>
      <li><a href="https://github.com/kubernetes/kube-ui">Setup instructions</a>
cluster.</li>
    </ul>
  </li>
</ul>

<h2 id="troubleshooting">Troubleshooting</h2>

<h3 id="running-validate-cluster">Running validate-cluster</h3>

<p><code class="highlighter-rouge">cluster/validate-cluster.sh</code> is used by <code class="highlighter-rouge">cluster/kube-up.sh</code> to determine if
the cluster start succeeded.</p>

<p>Example usage and output:</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="nv">KUBECTL_PATH</span><span class="o">=</span><span class="k">$(</span>which kubectl<span class="k">)</span> <span class="nv">NUM_NODES</span><span class="o">=</span>3 <span class="nv">KUBERNETES_PROVIDER</span><span class="o">=</span><span class="nb">local </span>cluster/validate-cluster.sh
Found 3 node<span class="o">(</span>s<span class="o">)</span>.
NAME                    STATUS    AGE
node1.local             Ready     1h
node2.local             Ready     1h
node3.local             Ready     1h
Validate output:
NAME                 STATUS    MESSAGE              ERROR
controller-manager   Healthy   ok
scheduler            Healthy   ok
etcd-1               Healthy   <span class="o">{</span><span class="s2">"health"</span>: <span class="s2">"true"</span><span class="o">}</span>
etcd-2               Healthy   <span class="o">{</span><span class="s2">"health"</span>: <span class="s2">"true"</span><span class="o">}</span>
etcd-0               Healthy   <span class="o">{</span><span class="s2">"health"</span>: <span class="s2">"true"</span><span class="o">}</span>
Cluster validation succeeded
</code></pre>
</div>

<h3 id="inspect-pods-and-services">Inspect pods and services</h3>

<p>Try to run through the “Inspect your cluster” section in one of the other Getting Started Guides, such as <a href="/docs/getting-started-guides/gce/#inspect-your-cluster">GCE</a>.
You should see some services.  You should also see “mirror pods” for the apiserver, scheduler and controller-manager, plus any add-ons you started.</p>

<h3 id="try-examples">Try Examples</h3>

<p>At this point you should be able to run through one of the basic examples, such as the <a href="/examples/simple-nginx">nginx example</a>.</p>

<h3 id="running-the-conformance-test">Running the Conformance Test</h3>

<p>You may want to try to run the <a href="http://releases.k8s.io/master/hack/conformance-test.sh">Conformance test</a>.  Any failures may give a hint as to areas that need more attention.</p>

<h3 id="networking-1">Networking</h3>

<p>The nodes must be able to connect to each other using their private IP. Verify this by
pinging or SSH-ing from one node to another.</p>

<h3 id="getting-help">Getting Help</h3>

<p>If you run into trouble, please see the section on <a href="/docs/getting-started-guides/gce#troubleshooting">troubleshooting</a>, post to the
<a href="https://groups.google.com/forum/#!forum/kubernetes-users">kubernetes-users group</a>, or come ask questions on <a href="/docs/troubleshooting#slack">Slack</a>.</p>

<h2 id="support-level">Support Level</h2>

<table>
  <thead>
    <tr>
      <th>IaaS Provider</th>
      <th>Config. Mgmt</th>
      <th>OS</th>
      <th>Networking</th>
      <th>Docs</th>
      <th>Conforms</th>
      <th>Support Level</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>any</td>
      <td>any</td>
      <td>any</td>
      <td>any</td>
      <td><a href="/docs/getting-started-guides/scratch">docs</a></td>
      <td> </td>
      <td>Community (<a href="https://github.com/erictune">@erictune</a>)</td>
    </tr>
  </tbody>
</table>

<p>For support level information on all solutions, see the <a href="/docs/getting-started-guides/#table-of-solutions">Table of solutions</a> chart.</p>


        <p><a href=""><img src="https://kubernetes-site.appspot.com/UA-36037335-10/GitHub/docs/getting-started-guides/scratch.md?pixel" alt="Analytics" /></a>
        
		<script type="text/javascript">
	        PDRTJS_settings_8345992 = {
		        "id" : "8345992",
		        "unique_id" : "/docs/getting-started-guides/scratch/",
		        "title" : "Creating a Custom Cluster from Scratch",
		        "permalink" : "http://kubernetes.github.io/docs/getting-started-guides/scratch/"
	        };
	        (function(d,c,j){if(!document.getElementById(j)){var pd=d.createElement(c),s;pd.id=j;pd.src=('https:'==document.location.protocol)?'https://polldaddy.com/js/rating/rating.js':'http://i0.poll.fm/js/rating/rating.js';s=document.getElementsByTagName(c)[0];s.parentNode.insertBefore(pd,s);}}(document,'script','pd-rating-js'));
		</script>
		<a href="" onclick="window.open('https://github.com/kubernetes/kubernetes.github.io/issues/new?title=Issue%20with%20' +
		window.location.pathname)" class="button issue">Create an Issue</a>
		<a href="/editdocs#docs/getting-started-guides/scratch.md" class="button issue">Edit this Page</a>
	
	</div>
</section>

<footer>
	<main class="light-text">
		<nav>
			<a href="/docs/hellonode/">Get Started</a>
			<a href="/docs/">Documentation</a>
			<a href="http://blog.kubernetes.io/">Blog</a>
			<a href="/partners/">Partners</a>
			<a href="/community/">Community</a>
			<a href="/case-studies/">Case Studies</a>
		</nav>
		<div class="social">
			<div>
				<a href="https://twitter.com/kubernetesio" class="twitter"><span>twitter</span></a>
				<a href="https://github.com/kubernetes/kubernetes" class="github"><span>Github</span></a>
				<a href="http://slack.k8s.io/" class="slack"><span>Slack</span></a>
			</div>
			<div>
				<a href="http://stackoverflow.com/questions/tagged/kubernetes" class="stack-overflow"><span>Stack Overflow</span></a>
				<a href="https://groups.google.com/forum/#!forum/kubernetes-users" class="mailing-list"><span>Mailing List</span></a>
				<a href="https://calendar.google.com/calendar/embed?src=nt2tcnbtbied3l6gi2h29slvc0%40group.calendar.google.com" class="calendar"><span>Events Calendar</span></a>
			</div>
			<div>
				<a href="//get.k8s.io" class="button">Download K8s</a>
				<a href="https://github.com/kubernetes/kubernetes" class="button">Contribute to the K8s codebase</a>
			</div>
		</div>
		<div id="miceType" class="center">
			&copy; 2017 The Kubernetes Authors | Documentation Distributed under <a href="https://github.com/kubernetes/kubernetes.github.io/blob/master/LICENSE" class="light-text">CC BY 4.0</a>
		</div>
		<div id="miceType" class="center">
			Copyright &copy; 2017 The Linux Foundation&reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our Trademark Usage page: <a href="https://www.linuxfoundation.org/trademark-usage" class="light-text">https://www.linuxfoundation.org/trademark-usage</a>
		</div>
	</main>
</footer>

<button class="flyout-button" onclick="kub.toggleToc()"></button>

<style>
.cse .gsc-control-cse, .gsc-control-cse, {
    padding: 0;
}
  .gsc-control-cse table, .gsc-control-cse-en table {
      margin:0px !important;
  }
  .gsc-above-wrapper-area {
      border-bottom: 0;
  }
</style>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-36037335-10', 'auto');
ga('send', 'pageview');

// hide docs nav area if no nav is present, or if nav only contains a link to the current page
(function () {
    window.addEventListener('DOMContentLoaded', init)

        // play nice with our neighbors
        function init() {
            window.removeEventListener('DOMContentLoaded', init)
                hideNav()
        }

    function hideNav(toc){
        if (!toc) toc = document.querySelector('#docsToc')
            var container = toc.querySelector('.container')

                // container is built dynamically, so it may not be present on the first runloop
                if (container) {
                    if (container.childElementCount === 0 || toc.querySelectorAll('a.item').length === 1) {
                        toc.style.display = 'none'
                            document.getElementById('docsContent').style.width = '100%'
                    }
                } else {
                    requestAnimationFrame(function () {
                        hideNav(toc)
                    })
                }
    }
})();
</script>

<!-- Commenting out AnswerDash for now; we need to work on our list of questions/answers/design first
    <!-- Start of AnswerDash script <script>var AnswerDash;!function(e,t,n,s,a){if(!t.getElementById(s)){var i,r=t.createElement(n),c=t.getElementsByTagName(n)[0];e[a]||(i=e[a]=function(){i.__oninit.push(arguments)},i.__oninit=[]),r.type="text/javascript",r.async=!0,r.src="https://p1.answerdash.com/answerdash.min.js?siteid=756",r.setAttribute("id",s),c.parentNode.insertBefore(r,c)}}(window,document,"script","answerdash-script","AnswerDash");</script> <!-- End of AnswerDash script -->


</body>
</html>
